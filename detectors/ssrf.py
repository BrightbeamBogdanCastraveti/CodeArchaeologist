"""
Module: ssrf.py
Author: Code Archaeologist Team
Purpose: Detect Server-Side Request Forgery (SSRF) vulnerabilities in Python code.

This detector finds SSRF patterns where AI commonly generates vulnerable code:
- User-controlled URLs in requests.get()
- Missing URL allowlist (Layer 1)
- Missing DNS resolution checks (Layer 2)
- Missing network egress controls (Layer 3 - documented)

ACADEMIC VALIDATION:
This detector is backed by peer-reviewed research:
"The Generative Code Security Crisis: Mapping Legacy OWASP Vulnerabilities
(2015-2025) Inherited by Large Language Models"

KEY RESEARCH FINDINGS:
- SSRF: HIGH prevalence in AI-generated code
- Training era: 2008-2020 (URL fetching tutorials without security)
- AI generates this because: SSRF defenses rarely mentioned in training data
- OWASP: A10:2025 - Server-Side Request Forgery

ZERO TRUST DEFENSE:
From "Expert Blueprint: Zero Trust Email Ingestion" (2024):
Layer 1: URL allowlist (code level)
Layer 2: DNS resolution + private IP blocking (code level)
Layer 3: FQDN filtering (infrastructure level)

CRITICAL: Max 400 lines per CLAUDE.md standards.
"""

import ast
import re
import sys
import os
from typing import List, Optional, Set
from dataclasses import dataclass

# Add research directory to path
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'research'))
try:
    from analysis_engine.research.academic_validation import get_cwe_research, explain_why_ai_generates
    from zero_trust_controls import A10_SSRF, check_missing_controls
    RESEARCH_AVAILABLE = True
except ImportError:
    RESEARCH_AVAILABLE = False


@dataclass
class SSRFFinding:
    """
    A detected SSRF vulnerability with missing defense layers.

    This finding includes not just the vulnerability, but which Zero Trust
    defense layers are MISSING.
    """
    pattern_id: str
    line: int
    column: int
    code_snippet: str
    severity: str
    confidence: int
    description: str
    user_controlled_var: str
    missing_layers: List[str]

    # Academic research backing
    cwe_id: str = "CWE-918"
    training_era: str = "2008-2020"
    owasp_category: str = "A10:2025 - SSRF"
    prevalence_vs_human: str = "High"
    academic_citation: str = "Zero Trust Email Ingestion Blueprint (2024)"

    def get_full_report(self) -> str:
        """
        Generate complete report with vulnerability AND missing defense layers.
        """
        report = f"""
SSRF DETECTED ({self.cwe_id})
================================================================================
Location: Line {self.line}, Column {self.column}
Severity: {self.severity} | Confidence: {self.confidence}%
Pattern: {self.pattern_id}

VULNERABLE CODE:
{self.code_snippet}

DESCRIPTION:
{self.description}
User-controlled variable: {self.user_controlled_var}

MISSING DEFENSE LAYERS:
"""
        for layer in self.missing_layers:
            report += f"âœ— {layer}\n"

        report += """
ATTACK EXAMPLES:
- AWS metadata: http://169.254.169.254/latest/meta-data/iam/security-credentials/
- Internal services: http://192.168.1.1:8080/admin
- Localhost: http://localhost:6379/ (Redis)

================================================================================
ACADEMIC RESEARCH VALIDATION
================================================================================
"""
        if RESEARCH_AVAILABLE:
            report += f"""
PREVALENCE IN AI CODE: {self.prevalence_vs_human}

TRAINING ERA: {self.training_era}

WHY AI GENERATES THIS VULNERABILITY:
Training data (2010-2020) showed URL fetching without security context.
StackOverflow #22676 (2008, 5000+ upvotes) used requests.get(url) directly.
SSRF defenses weren't mentioned in tutorials until ~2018-2019.

OWASP CATEGORY: {self.owasp_category}

ZERO TRUST REQUIREMENT:
All 3 layers MUST be present (from "Expert Blueprint: Zero Trust Email Ingestion")

Layer 1: URL allowlist with explicit permitted domains
Layer 2: DNS resolution + private IP blocking (RFC1918, 169.254.0.0/16)
Layer 3: FQDN filtering at network/infrastructure level

REAL-WORLD IMPACT:
- AWS credentials theft (Capital One breach)
- Internal network scanning
- Localhost service access (Redis, PostgreSQL)

ACADEMIC SOURCE:
{self.academic_citation}
"""
        return report


class SSRFDetector:
    """
    Detects SSRF vulnerabilities using AST analysis.

    Focuses on AI-generated patterns where developers fetch URLs
    without implementing 3-layer defense.
    """

    # HTTP libraries that can cause SSRF
    HTTP_FUNCTIONS = {
        'requests.get', 'requests.post', 'requests.put', 'requests.delete',
        'requests.request', 'urllib.request.urlopen', 'urllib2.urlopen',
        'httplib.HTTPConnection', 'http.client.HTTPConnection',
        'urllib3.request', 'httpx.get', 'httpx.post',
        'selenium.webdriver', 'playwright'
    }

    # User input sources (taint sources)
    USER_INPUT_SOURCES = {
        'request.GET', 'request.POST', 'request.DATA', 'request.data',
        'request.query_params', 'request.form', 'request.args',
        'request.values', 'request.json', 'request.body'
    }

    # Variables that suggest user input
    SUSPICIOUS_VAR_NAMES = {
        'url', 'uri', 'link', 'profile_url', 'webhook_url', 'callback_url',
        'redirect_url', 'avatar_url', 'image_url', 'cv_url', 'resume_url',
        'linkedin_url', 'github_url', 'api_url', 'endpoint'
    }

    def __init__(self):
        """Initialize the SSRF detector."""
        self.findings: List[SSRFFinding] = []
        self.url_allowlist_present = False
        self.dns_check_present = False
        self.ip_check_present = False

    def detect(self, source_code: str, file_path: str) -> List[SSRFFinding]:
        """
        Detect SSRF vulnerabilities in source code.

        Args:
            source_code: Python source code to analyze
            file_path: Path to the file being analyzed

        Returns:
            List of SSRF findings
        """
        self.findings = []

        try:
            tree = ast.parse(source_code)
            self._analyze_file_for_defenses(tree, source_code)
            self._analyze_ast(tree, source_code)
        except SyntaxError:
            return self.findings

        return self.findings

    def _analyze_file_for_defenses(self, tree: ast.AST, source_code: str) -> None:
        """
        Check if file contains defense mechanisms.

        Args:
            tree: AST of the source code
            source_code: Original source code
        """
        # Check for ALLOWED_DOMAINS constant (Layer 1)
        if 'ALLOWED_DOMAINS' in source_code or 'ALLOWED_URLS' in source_code:
            self.url_allowlist_present = True

        # Check for DNS resolution (Layer 2)
        if 'gethostbyname' in source_code or 'getaddrinfo' in source_code:
            self.dns_check_present = True

        # Check for IP address checks (Layer 2)
        if 'ipaddress' in source_code or 'is_private' in source_code:
            self.ip_check_present = True

    def _analyze_ast(self, tree: ast.AST, source_code: str) -> None:
        """
        Analyze the AST for SSRF patterns.

        Args:
            tree: AST of the source code
            source_code: Original source code for context
        """
        for node in ast.walk(tree):
            if isinstance(node, ast.Call):
                self._check_http_call(node, source_code)

    def _check_http_call(self, node: ast.Call, source_code: str) -> None:
        """
        Check if an HTTP call uses user-controlled URL.

        Args:
            node: ast.Call node
            source_code: Source code for context
        """
        func_name = self._get_function_name(node)

        if not func_name or not self._is_http_function(func_name):
            return

        # Check first argument (URL)
        if not node.args:
            return

        url_arg = node.args[0]

        # Check if URL is user-controlled
        is_tainted, var_name = self._is_url_tainted(url_arg)

        if not is_tainted:
            return

        # Determine which layers are missing
        missing_layers = []

        # Check within the function scope
        function_has_allowlist = self._check_local_allowlist(node, source_code)
        function_has_ip_check = self._check_local_ip_check(node, source_code)

        if not (self.url_allowlist_present or function_has_allowlist):
            missing_layers.append("Layer 1: URL allowlist")

        if not (self.dns_check_present or self.ip_check_present or function_has_ip_check):
            missing_layers.append("Layer 2: DNS resolution + private IP check")

        # Layer 3 is always "missing" at code level (infrastructure concern)
        missing_layers.append("Layer 3: Network egress control (infrastructure)")

        # Create finding
        code_snippet = ast.get_source_segment(source_code, node) or "Unable to extract"

        # Calculate confidence based on context
        confidence = self._calculate_confidence(var_name, missing_layers)

        finding = SSRFFinding(
            pattern_id="SSRF_USER_CONTROLLED_URL",
            line=node.lineno,
            column=node.col_offset,
            code_snippet=code_snippet,
            severity="CRITICAL" if len(missing_layers) >= 2 else "HIGH",
            confidence=confidence,
            description=f"HTTP request with user-controlled URL: {func_name}()",
            user_controlled_var=var_name,
            missing_layers=missing_layers
        )

        self.findings.append(finding)

    def _is_http_function(self, func_name: str) -> bool:
        """
        Check if function name is an HTTP library function.

        Args:
            func_name: Function name to check

        Returns:
            True if HTTP function
        """
        return any(http_func in func_name for http_func in self.HTTP_FUNCTIONS)

    def _get_function_name(self, node: ast.Call) -> Optional[str]:
        """
        Extract fully qualified function name from Call node.

        Args:
            node: ast.Call node

        Returns:
            Function name or None
        """
        if isinstance(node.func, ast.Attribute):
            # requests.get, urllib.request.urlopen
            parts = []
            current = node.func

            while isinstance(current, ast.Attribute):
                parts.append(current.attr)
                current = current.value

            if isinstance(current, ast.Name):
                parts.append(current.id)

            return '.'.join(reversed(parts))

        elif isinstance(node.func, ast.Name):
            return node.func.id

        return None

    def _is_url_tainted(self, node: ast.AST) -> tuple[bool, str]:
        """
        Check if URL argument is potentially user-controlled.

        Args:
            node: AST node representing URL argument

        Returns:
            (is_tainted, variable_name)
        """
        # Check for direct request.GET/POST access
        if isinstance(node, ast.Subscript):
            value_name = self._get_node_name(node.value)
            if any(source in value_name for source in self.USER_INPUT_SOURCES):
                return (True, value_name)

        # Check for .get() method on request
        if isinstance(node, ast.Call):
            if isinstance(node.func, ast.Attribute):
                if node.func.attr == 'get':
                    value_name = self._get_node_name(node.func.value)
                    if any(source in value_name for source in self.USER_INPUT_SOURCES):
                        return (True, value_name)

        # Check variable name
        if isinstance(node, ast.Name):
            if node.id.lower() in self.SUSPICIOUS_VAR_NAMES:
                return (True, node.id)

        # Check for f-strings or format with variables
        if isinstance(node, ast.JoinedStr):
            return (True, "f-string with variables")

        # Conservative: any variable could be tainted
        if isinstance(node, ast.Name):
            return (True, node.id)

        return (False, "")

    def _get_node_name(self, node: ast.AST) -> str:
        """
        Get string representation of AST node.

        Args:
            node: AST node

        Returns:
            String representation
        """
        if isinstance(node, ast.Name):
            return node.id
        elif isinstance(node, ast.Attribute):
            value_name = self._get_node_name(node.value)
            return f"{value_name}.{node.attr}"
        return ""

    def _check_local_allowlist(self, node: ast.Call, source_code: str) -> bool:
        """
        Check if there's an allowlist check near this call.

        Args:
            node: Call node
            source_code: Source code

        Returns:
            True if allowlist check found nearby
        """
        # Get surrounding lines
        start_line = max(0, node.lineno - 10)
        end_line = node.lineno

        lines = source_code.split('\n')[start_line:end_line]
        context = '\n'.join(lines)

        # Look for allowlist patterns
        allowlist_patterns = [
            r'ALLOWED_DOMAINS',
            r'ALLOWED_URLS',
            r'if.*in.*allowed',
            r'whitelist'
        ]

        return any(re.search(pattern, context, re.IGNORECASE) for pattern in allowlist_patterns)

    def _check_local_ip_check(self, node: ast.Call, source_code: str) -> bool:
        """
        Check if there's an IP check near this call.

        Args:
            node: Call node
            source_code: Source code

        Returns:
            True if IP check found nearby
        """
        start_line = max(0, node.lineno - 10)
        end_line = node.lineno

        lines = source_code.split('\n')[start_line:end_line]
        context = '\n'.join(lines)

        # Look for IP check patterns
        ip_check_patterns = [
            r'gethostbyname',
            r'ipaddress',
            r'is_private',
            r'169\.254\.169\.254',
            r'RFC1918',
            r'private.*ip'
        ]

        return any(re.search(pattern, context, re.IGNORECASE) for pattern in ip_check_patterns)

    def _calculate_confidence(self, var_name: str, missing_layers: List[str]) -> int:
        """
        Calculate confidence score for finding.

        Args:
            var_name: Variable name used for URL
            missing_layers: List of missing defense layers

        Returns:
            Confidence score (0-100)
        """
        base_score = 70

        # Higher confidence for obvious user input
        if any(source in var_name for source in self.USER_INPUT_SOURCES):
            base_score = 95

        # Higher confidence for suspicious variable names
        if any(suspicious in var_name.lower() for suspicious in self.SUSPICIOUS_VAR_NAMES):
            base_score = min(base_score + 10, 95)

        # More missing layers = higher confidence
        if len(missing_layers) >= 3:
            base_score = min(base_score + 10, 98)

        return base_score
